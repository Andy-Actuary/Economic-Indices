# Code Block 3 - updated the series_id with desired metric
import requests
import json
import pandas as pd
from datetime import datetime

# Your BLS API key
# You'll need an API key from BLS (Andy registered... https://www.bls.gov/developers/termsOfService.htm)
api_key = '92ce469537d9415192489915e4e1d0c2'

#  this should be the only thing you need to update
series_id = 'WPUSI012011'

# Current year and previous year
current_year = datetime.now().year
previous_year = earliest # hardcode the year

# Function to fetch data in chunks
def fetch_data_in_chunks(series_id, start_year, end_year, chunk_size=20):
    all_data = []
    for year in range(start_year, end_year + 1, chunk_size):
        # API request parameters
        headers = {'Content-type': 'application/json'}
        data = json.dumps({
            "seriesid": [series_id],
            "startyear": str(year),
            "endyear": str(min(year + chunk_size - 1, end_year)),
            "registrationkey": api_key
        })

        # Submit the request
        response = requests.post('https://api.bls.gov/publicAPI/v2/timeseries/data/',
                                data=data, headers=headers)

        # Parse the response
        json_data = json.loads(response.text)

        # Check for a successful request
        if json_data['status'] == 'REQUEST_SUCCEEDED':
            # Extract the data
            series_data = json_data['Results']['series'][0]['data']
            all_data.extend(series_data)
        else:
            print("Error: ", json_data['status'])
            print(json_data['message'])
            return None  # Return None if an error occurs

    return all_data

# Fetch data using the chunking function
all_series_data = fetch_data_in_chunks(series_id, previous_year, current_year)

if all_series_data:
    # Convert to DataFrame
    df = pd.DataFrame(all_series_data)

    # Format the data
    df['value'] = df['value'].astype(float)
    df['period'] = df['period'].str.replace('M', '')
    df['date'] = pd.to_datetime(df['year'] + '-' + df['period'] + '-01').dt.strftime('%Y-%m-%d')

    # Sort by date
    df = df.sort_values('date')

    # Calculate 12-month moving average
    df['12_month_MA'] = df['value'].rolling(window=12).mean()

    # Calculate percentage change based on 12-month moving average
    df['MA_pct_change1'] = df['12_month_MA'].pct_change(periods=12)
    df['MA_pct_change'] = df['MA_pct_change1'].map("{:.2%}".format)

    # Select desired columns (including 'date')
    df = df[['date', 'value', '12_month_MA', 'MA_pct_change']]

!pip install beautifulsoup4
!pip install lxml

# URL of the webpage  to pull the Series Title, Series ID	, Seasonality	, Survey Name	, Measure Data Type	, Industry, Sector ,Item,
url = f'https://data.bls.gov/dataViewer/view/timeseries/{series_id}'

# Read the HTML tables from the URL
tables = pd.read_html(url)

# Extract the desired table (table 3)
series_info_table = tables[2]  # Index 2 for table 3 (ordering goes 0,1,2,3, etc.)

# Select columns 0 and 2 (ordering goes 0,1,2,3, etc.)
selected_data = series_info_table[[series_info_table.columns[0], series_info_table.columns[2]]]

# Display the selected data
display(selected_data)

# Transpose selected_data and set column headers
selected_data_T = selected_data.set_index(0).T  # Transpose and set column 0 as index
selected_data_T.columns = selected_data_T.columns.str.strip()  # (Optional) Remove leading/trailing spaces in column names

# Update 'df' with selected_data
for col in selected_data_T.columns:
    if col not in df.columns:  # Add new columns if they don't exist
        # Use .iloc[0, selected_data_T.columns.get_loc(col)] to access the first row and the column by its name
        df[col] = selected_data_T.iloc[0, selected_data_T.columns.get_loc(col)]

display(df)
print("Data:")
print(df)
    # Export to Excel (including index as 'date')
#df.to_excel('df_Check1.xlsx', index=True, index_label='date')
